{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Baseline-Flair",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deniskapel/ner-dialogues-hackathon/blob/master/Baseline_Flair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2Cz7kw7cFph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b11f4147-4188-4153-c937-eb68d45a5016"
      },
      "source": [
        "!pip install flair"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/a0/a1b41fa2fcb23ff71ba9148af75211dcccc35b256dea821b36e1ee871848/flair-0.7-py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 8.2MB/s \n",
            "\u001b[?25hCollecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/2d/b1d99e9ad157dd7de9cd0d36a8a5876b13b55e4b75f7498bc96035fb4e96/sqlitedict-1.7.0.tar.gz\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.7)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/56/7d4774533d2c119e1873993d34d313c9c9efc88c5e4ab7e33bdf915ad98c/Deprecated-1.2.11-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from flair) (4.2.6)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.7.0+cu101)\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e2/3b51c53dffb1e52d9210ebc01f1fb9f2f6eba9b3201fa971fd3946643c71/ftfy-5.8.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.9MB/s \n",
            "\u001b[?25hCollecting transformers<=3.5.1,>=3.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 14.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Collecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/01/47358efec5396fc80f98273c42cbdfe7aab056252b07884ffcc0f118978f/konoha-4.6.2-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.2.2)\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/91/77/3f0f53856e86af32b1d3c86652815277f7b5f880002584eb30db115b6df5/bpemb-0.3.2-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.22.2.post1)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 46.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Collecting sentencepiece<=0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 31.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 33.7MB/s \n",
            "\u001b[?25hCollecting janome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7MB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (1.19.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (3.7.4.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->flair) (3.0.12)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 24.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->flair) (2.23.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->flair) (3.12.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->flair) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 21.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.5)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.11.3)\n",
            "Collecting overrides==3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/42/8d/caa729f809ecdf8e76fac3c1ff7d3f0b72c398c9dd8a6919927a30a873b3/overrides-3.0.0.tar.gz\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (4.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<=3.5.1,>=3.5.0->flair) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<=3.5.1,>=3.5.0->flair) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<=3.5.1,>=3.5.0->flair) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<=3.5.1,>=3.5.0->flair) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers<=3.5.1,>=3.5.0->flair) (53.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<=3.5.1,>=3.5.0->flair) (7.1.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Building wheels for collected packages: sqlitedict, ftfy, langdetect, segtok, mpld3, sacremoses, overrides\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-cp36-none-any.whl size=14376 sha256=0f62e7ee50df56c84c2f064e94f300f9ea0790cd2cbfb1a424b7c59980980486\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/c6/4f/2c64a43f041415eb8b8740bd80e15e92f0d46c5e464d8e4b9b\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.8-cp36-none-any.whl size=45613 sha256=8a47d93a0ddc8ae7885b49ff9ddd5d536a5e2a63cfab2580aa58223c21b46058\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/c0/ef/f28c4da5ac84a4e06ac256ca9182fc34fa57fefffdbc68425b\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993194 sha256=c8060d3f404c234e07cdba4838edcb8b97258271cb90aa1044e8e03e41e87f19\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp36-none-any.whl size=25019 sha256=12fe1a28d080882c699f676252d57b0ddd0213e8974d29ebee39237b50b3570b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116678 sha256=cb942e9aecf1f43681421be483ab8f41ba8fe793d1be1261cb57f8459f6da66b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=3bc704b3f8411fdf16127dcbe8abd1d6374fc5ba69c14ff580c7c832bae5e382\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.0.0-cp36-none-any.whl size=5669 sha256=a37eab564ab19c254185ebf7a1f4b6ce20fcdf8fa8714f3cde8747f27ed01522\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/1b/ec/6c71a1eb823df7f850d956b2d8c50a6d49c191e1063d73b9be\n",
            "Successfully built sqlitedict ftfy langdetect segtok mpld3 sacremoses overrides\n",
            "Installing collected packages: sqlitedict, deprecated, ftfy, sentencepiece, tokenizers, sacremoses, transformers, overrides, konoha, bpemb, langdetect, segtok, mpld3, janome, flair\n",
            "Successfully installed bpemb-0.3.2 deprecated-1.2.11 flair-0.7 ftfy-5.8 janome-0.4.1 konoha-4.6.2 langdetect-1.0.8 mpld3-0.3 overrides-3.0.0 sacremoses-0.0.43 segtok-1.5.10 sentencepiece-0.1.91 sqlitedict-1.7.0 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcJLr30xcFpm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2447ca8-e85c-4ca3-9bbf-63ebf6af7b0f"
      },
      "source": [
        "# Uncomment if you need to download data\n",
        "!wget https://raw.githubusercontent.com/Rexhaif/ner-dialogues-hackathon/master/data/train.conll\n",
        "!wget https://raw.githubusercontent.com/Rexhaif/ner-dialogues-hackathon/master/data/dev.conll\n",
        "!wget https://raw.githubusercontent.com/Rexhaif/ner-dialogues-hackathon/master/data/test.conll"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-09 15:37:22--  https://raw.githubusercontent.com/Rexhaif/ner-dialogues-hackathon/master/data/train.conll\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 125059 (122K) [text/plain]\n",
            "Saving to: ‘train.conll’\n",
            "\n",
            "train.conll         100%[===================>] 122.13K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-02-09 15:37:23 (8.04 MB/s) - ‘train.conll’ saved [125059/125059]\n",
            "\n",
            "--2021-02-09 15:37:23--  https://raw.githubusercontent.com/Rexhaif/ner-dialogues-hackathon/master/data/dev.conll\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14109 (14K) [text/plain]\n",
            "Saving to: ‘dev.conll’\n",
            "\n",
            "dev.conll           100%[===================>]  13.78K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-02-09 15:37:23 (109 MB/s) - ‘dev.conll’ saved [14109/14109]\n",
            "\n",
            "--2021-02-09 15:37:23--  https://raw.githubusercontent.com/Rexhaif/ner-dialogues-hackathon/master/data/test.conll\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34661 (34K) [text/plain]\n",
            "Saving to: ‘test.conll’\n",
            "\n",
            "test.conll          100%[===================>]  33.85K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2021-02-09 15:37:23 (17.8 MB/s) - ‘test.conll’ saved [34661/34661]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58vdRL76cFpn"
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, CharacterEmbeddings, FlairEmbeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caeJiG7HcFpo"
      },
      "source": [
        "import flair\n",
        "import torch\n",
        "# uncomment for cpu-only training\n",
        "# flair.device = torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wwj8Rx1cFpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c3bc82-3966-4c29-e847-c9f04ab4f05d"
      },
      "source": [
        "# 1. get the corpus\n",
        "corpus: Corpus = ColumnCorpus(\n",
        "    \"./\", column_format={0:'text', 1:'ner'},\n",
        "    train_file='train.conll', dev_file='dev.conll', test_file='test.conll',\n",
        ")\n",
        "print(corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-09 15:39:35,653 Reading data from .\n",
            "2021-02-09 15:39:35,658 Train: train.conll\n",
            "2021-02-09 15:39:35,659 Dev: dev.conll\n",
            "2021-02-09 15:39:35,661 Test: test.conll\n",
            "Corpus: 1966 train + 219 dev + 547 test sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDL5yERzcFpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8945679-b956-4837-d47e-75e18ef397d1"
      },
      "source": [
        "# 2. what tag do we want to predict?\n",
        "tag_type = 'ner'\n",
        "\n",
        "# 3. make the tag dictionary from the corpus\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
        "print(tag_dictionary)\n",
        "\n",
        "# 4. initialize embeddings\n",
        "embedding_types = [\n",
        "    # standard word embeddings\n",
        "    WordEmbeddings('glove'),\n",
        "    CharacterEmbeddings()\n",
        "]\n",
        "\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dictionary with 14 tags: <unk>, O, B-SINGER, I-SINGER, B-SONG, B-FILM, I-SONG, I-FILM, B-COMPOSER, I-COMPOSER, B-BOOK, I-BOOK, <START>, <STOP>\n",
            "2021-02-09 16:08:05,589 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmp76fsa7ae\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 160000128/160000128 [00:09<00:00, 16483738.92B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-09 16:08:15,775 copying /tmp/tmp76fsa7ae to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-09 16:08:16,051 removing temp file /tmp/tmp76fsa7ae\n",
            "2021-02-09 16:08:16,726 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to /tmp/tmpab7gfsl0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 21494764/21494764 [00:02<00:00, 10152404.42B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-09 16:08:19,313 copying /tmp/tmpab7gfsl0 to cache at /root/.flair/embeddings/glove.gensim\n",
            "2021-02-09 16:08:19,339 removing temp file /tmp/tmpab7gfsl0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HLrdzLccFpp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d28cd3-9693-4005-faba-47d4b41a6925"
      },
      "source": [
        "# 5. initialize sequence tagger\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "                                        embeddings=embeddings,\n",
        "                                        tag_dictionary=tag_dictionary,\n",
        "                                        tag_type=tag_type,\n",
        "                                        use_crf=True)\n",
        "\n",
        "# 6. initialize trainer\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# 7. start training\n",
        "history = trainer.train(\n",
        "    './models/baseline-charembeddings',\n",
        "    learning_rate=0.1,\n",
        "    mini_batch_size=32,\n",
        "    max_epochs=20\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-09 16:08:21,023 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:08:21,027 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('glove')\n",
            "    (list_embedding_1): CharacterEmbeddings(\n",
            "      (char_embedding): Embedding(275, 25)\n",
            "      (char_rnn): LSTM(25, 25, bidirectional=True)\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=150, out_features=150, bias=True)\n",
            "  (rnn): LSTM(150, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=14, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2021-02-09 16:08:21,028 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:08:21,030 Corpus: \"Corpus: 1966 train + 219 dev + 547 test sentences\"\n",
            "2021-02-09 16:08:21,033 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:08:21,034 Parameters:\n",
            "2021-02-09 16:08:21,036  - learning_rate: \"0.1\"\n",
            "2021-02-09 16:08:21,037  - mini_batch_size: \"32\"\n",
            "2021-02-09 16:08:21,038  - patience: \"3\"\n",
            "2021-02-09 16:08:21,040  - anneal_factor: \"0.5\"\n",
            "2021-02-09 16:08:21,041  - max_epochs: \"20\"\n",
            "2021-02-09 16:08:21,042  - shuffle: \"True\"\n",
            "2021-02-09 16:08:21,043  - train_with_dev: \"False\"\n",
            "2021-02-09 16:08:21,044  - batch_growth_annealing: \"False\"\n",
            "2021-02-09 16:08:21,045 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:08:21,046 Model training base path: \"models/baseline-charembeddings\"\n",
            "2021-02-09 16:08:21,047 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:08:21,048 Device: cpu\n",
            "2021-02-09 16:08:21,049 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:08:21,049 Embeddings storage mode: cpu\n",
            "2021-02-09 16:08:21,051 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:08:22,750 epoch 1 - iter 6/62 - loss 8.31826560 - samples/sec: 113.77 - lr: 0.100000\n",
            "2021-02-09 16:08:24,277 epoch 1 - iter 12/62 - loss 7.45352364 - samples/sec: 125.98 - lr: 0.100000\n",
            "2021-02-09 16:08:25,816 epoch 1 - iter 18/62 - loss 6.98371553 - samples/sec: 124.88 - lr: 0.100000\n",
            "2021-02-09 16:08:27,411 epoch 1 - iter 24/62 - loss 6.71521552 - samples/sec: 120.51 - lr: 0.100000\n",
            "2021-02-09 16:08:28,932 epoch 1 - iter 30/62 - loss 6.40991772 - samples/sec: 126.37 - lr: 0.100000\n",
            "2021-02-09 16:08:30,538 epoch 1 - iter 36/62 - loss 6.21293141 - samples/sec: 119.64 - lr: 0.100000\n",
            "2021-02-09 16:08:32,090 epoch 1 - iter 42/62 - loss 6.03175552 - samples/sec: 123.84 - lr: 0.100000\n",
            "2021-02-09 16:08:33,628 epoch 1 - iter 48/62 - loss 5.84994056 - samples/sec: 124.98 - lr: 0.100000\n",
            "2021-02-09 16:08:35,219 epoch 1 - iter 54/62 - loss 5.72060440 - samples/sec: 120.85 - lr: 0.100000\n",
            "2021-02-09 16:08:36,803 epoch 1 - iter 60/62 - loss 5.65289931 - samples/sec: 121.47 - lr: 0.100000\n",
            "2021-02-09 16:08:37,207 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:08:37,208 EPOCH 1 done: loss 5.6040 - lr 0.1000000\n",
            "2021-02-09 16:08:37,671 DEV : loss 4.819207668304443 - score 0.2335\n",
            "2021-02-09 16:08:37,679 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-09 16:08:40,915 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:08:42,753 epoch 2 - iter 6/62 - loss 4.84037550 - samples/sec: 104.63 - lr: 0.100000\n",
            "2021-02-09 16:08:44,453 epoch 2 - iter 12/62 - loss 4.46208159 - samples/sec: 113.08 - lr: 0.100000\n",
            "2021-02-09 16:08:46,371 epoch 2 - iter 18/62 - loss 4.54089073 - samples/sec: 100.21 - lr: 0.100000\n",
            "2021-02-09 16:08:48,091 epoch 2 - iter 24/62 - loss 4.37104372 - samples/sec: 111.74 - lr: 0.100000\n",
            "2021-02-09 16:08:49,807 epoch 2 - iter 30/62 - loss 4.25869292 - samples/sec: 111.98 - lr: 0.100000\n",
            "2021-02-09 16:08:51,616 epoch 2 - iter 36/62 - loss 4.21076771 - samples/sec: 106.25 - lr: 0.100000\n",
            "2021-02-09 16:08:53,345 epoch 2 - iter 42/62 - loss 4.15347626 - samples/sec: 111.20 - lr: 0.100000\n",
            "2021-02-09 16:08:55,176 epoch 2 - iter 48/62 - loss 4.11479269 - samples/sec: 105.03 - lr: 0.100000\n",
            "2021-02-09 16:08:56,970 epoch 2 - iter 54/62 - loss 4.09284376 - samples/sec: 107.12 - lr: 0.100000\n",
            "2021-02-09 16:08:58,838 epoch 2 - iter 60/62 - loss 4.03620374 - samples/sec: 102.88 - lr: 0.100000\n",
            "2021-02-09 16:08:59,362 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:08:59,363 EPOCH 2 done: loss 4.0127 - lr 0.1000000\n",
            "2021-02-09 16:08:59,866 DEV : loss 3.9783987998962402 - score 0.31\n",
            "2021-02-09 16:08:59,873 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-09 16:09:02,626 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:09:04,510 epoch 3 - iter 6/62 - loss 3.71993526 - samples/sec: 102.26 - lr: 0.100000\n",
            "2021-02-09 16:09:06,468 epoch 3 - iter 12/62 - loss 3.81648346 - samples/sec: 98.28 - lr: 0.100000\n",
            "2021-02-09 16:09:08,323 epoch 3 - iter 18/62 - loss 3.70521959 - samples/sec: 103.76 - lr: 0.100000\n",
            "2021-02-09 16:09:10,167 epoch 3 - iter 24/62 - loss 3.69432949 - samples/sec: 104.25 - lr: 0.100000\n",
            "2021-02-09 16:09:12,029 epoch 3 - iter 30/62 - loss 3.63167851 - samples/sec: 103.21 - lr: 0.100000\n",
            "2021-02-09 16:09:13,807 epoch 3 - iter 36/62 - loss 3.49879314 - samples/sec: 108.04 - lr: 0.100000\n",
            "2021-02-09 16:09:15,674 epoch 3 - iter 42/62 - loss 3.44326574 - samples/sec: 102.98 - lr: 0.100000\n",
            "2021-02-09 16:09:17,572 epoch 3 - iter 48/62 - loss 3.44632784 - samples/sec: 101.27 - lr: 0.100000\n",
            "2021-02-09 16:09:19,396 epoch 3 - iter 54/62 - loss 3.40657151 - samples/sec: 105.35 - lr: 0.100000\n",
            "2021-02-09 16:09:21,303 epoch 3 - iter 60/62 - loss 3.41634449 - samples/sec: 100.75 - lr: 0.100000\n",
            "2021-02-09 16:09:21,814 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:09:21,816 EPOCH 3 done: loss 3.3993 - lr 0.1000000\n",
            "2021-02-09 16:09:22,311 DEV : loss 3.4706451892852783 - score 0.3312\n",
            "2021-02-09 16:09:22,316 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-09 16:09:25,079 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:09:26,999 epoch 4 - iter 6/62 - loss 3.13790663 - samples/sec: 100.17 - lr: 0.100000\n",
            "2021-02-09 16:09:28,892 epoch 4 - iter 12/62 - loss 3.13499272 - samples/sec: 101.51 - lr: 0.100000\n",
            "2021-02-09 16:09:30,837 epoch 4 - iter 18/62 - loss 3.10679004 - samples/sec: 98.82 - lr: 0.100000\n",
            "2021-02-09 16:09:32,780 epoch 4 - iter 24/62 - loss 3.10541755 - samples/sec: 98.89 - lr: 0.100000\n",
            "2021-02-09 16:09:34,693 epoch 4 - iter 30/62 - loss 3.14228974 - samples/sec: 100.45 - lr: 0.100000\n",
            "2021-02-09 16:09:36,540 epoch 4 - iter 36/62 - loss 3.10469670 - samples/sec: 104.11 - lr: 0.100000\n",
            "2021-02-09 16:09:38,420 epoch 4 - iter 42/62 - loss 3.10761521 - samples/sec: 102.20 - lr: 0.100000\n",
            "2021-02-09 16:09:40,387 epoch 4 - iter 48/62 - loss 3.11788658 - samples/sec: 97.67 - lr: 0.100000\n",
            "2021-02-09 16:09:42,275 epoch 4 - iter 54/62 - loss 3.07771067 - samples/sec: 101.96 - lr: 0.100000\n",
            "2021-02-09 16:09:44,225 epoch 4 - iter 60/62 - loss 3.04745921 - samples/sec: 98.54 - lr: 0.100000\n",
            "2021-02-09 16:09:44,744 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:09:44,747 EPOCH 4 done: loss 3.0411 - lr 0.1000000\n",
            "2021-02-09 16:09:45,236 DEV : loss 3.102627992630005 - score 0.3298\n",
            "2021-02-09 16:09:45,244 BAD EPOCHS (no improvement): 1\n",
            "2021-02-09 16:09:45,245 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:09:47,151 epoch 5 - iter 6/62 - loss 2.86003264 - samples/sec: 100.89 - lr: 0.100000\n",
            "2021-02-09 16:09:49,086 epoch 5 - iter 12/62 - loss 2.92302056 - samples/sec: 99.28 - lr: 0.100000\n",
            "2021-02-09 16:09:50,910 epoch 5 - iter 18/62 - loss 2.81641991 - samples/sec: 105.40 - lr: 0.100000\n",
            "2021-02-09 16:09:52,745 epoch 5 - iter 24/62 - loss 2.79091580 - samples/sec: 104.72 - lr: 0.100000\n",
            "2021-02-09 16:09:54,800 epoch 5 - iter 30/62 - loss 2.78851690 - samples/sec: 93.53 - lr: 0.100000\n",
            "2021-02-09 16:09:56,710 epoch 5 - iter 36/62 - loss 2.73950533 - samples/sec: 100.59 - lr: 0.100000\n",
            "2021-02-09 16:09:58,654 epoch 5 - iter 42/62 - loss 2.76221858 - samples/sec: 98.85 - lr: 0.100000\n",
            "2021-02-09 16:10:00,736 epoch 5 - iter 48/62 - loss 2.74843011 - samples/sec: 92.27 - lr: 0.100000\n",
            "2021-02-09 16:10:02,657 epoch 5 - iter 54/62 - loss 2.73527929 - samples/sec: 100.09 - lr: 0.100000\n",
            "2021-02-09 16:10:04,563 epoch 5 - iter 60/62 - loss 2.73342061 - samples/sec: 100.79 - lr: 0.100000\n",
            "2021-02-09 16:10:05,027 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:10:05,029 EPOCH 5 done: loss 2.7400 - lr 0.1000000\n",
            "2021-02-09 16:10:05,549 DEV : loss 2.7771832942962646 - score 0.4025\n",
            "2021-02-09 16:10:05,555 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-09 16:10:08,309 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:10:10,283 epoch 6 - iter 6/62 - loss 2.61603407 - samples/sec: 97.40 - lr: 0.100000\n",
            "2021-02-09 16:10:12,292 epoch 6 - iter 12/62 - loss 2.57452951 - samples/sec: 95.67 - lr: 0.100000\n",
            "2021-02-09 16:10:14,325 epoch 6 - iter 18/62 - loss 2.53612967 - samples/sec: 94.62 - lr: 0.100000\n",
            "2021-02-09 16:10:16,267 epoch 6 - iter 24/62 - loss 2.57258422 - samples/sec: 98.98 - lr: 0.100000\n",
            "2021-02-09 16:10:18,364 epoch 6 - iter 30/62 - loss 2.54628365 - samples/sec: 91.64 - lr: 0.100000\n",
            "2021-02-09 16:10:20,295 epoch 6 - iter 36/62 - loss 2.52095370 - samples/sec: 99.54 - lr: 0.100000\n",
            "2021-02-09 16:10:22,263 epoch 6 - iter 42/62 - loss 2.52955462 - samples/sec: 97.66 - lr: 0.100000\n",
            "2021-02-09 16:10:24,210 epoch 6 - iter 48/62 - loss 2.52580897 - samples/sec: 98.72 - lr: 0.100000\n",
            "2021-02-09 16:10:26,295 epoch 6 - iter 54/62 - loss 2.51836934 - samples/sec: 92.19 - lr: 0.100000\n",
            "2021-02-09 16:10:28,252 epoch 6 - iter 60/62 - loss 2.50511280 - samples/sec: 98.19 - lr: 0.100000\n",
            "2021-02-09 16:10:28,768 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:10:28,772 EPOCH 6 done: loss 2.4965 - lr 0.1000000\n",
            "2021-02-09 16:10:29,322 DEV : loss 2.543687582015991 - score 0.4381\n",
            "2021-02-09 16:10:29,326 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-09 16:10:32,077 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:10:34,102 epoch 7 - iter 6/62 - loss 2.45159976 - samples/sec: 94.92 - lr: 0.100000\n",
            "2021-02-09 16:10:36,122 epoch 7 - iter 12/62 - loss 2.47238744 - samples/sec: 95.12 - lr: 0.100000\n",
            "2021-02-09 16:10:38,107 epoch 7 - iter 18/62 - loss 2.42015515 - samples/sec: 96.94 - lr: 0.100000\n",
            "2021-02-09 16:10:40,001 epoch 7 - iter 24/62 - loss 2.35477913 - samples/sec: 101.49 - lr: 0.100000\n",
            "2021-02-09 16:10:41,840 epoch 7 - iter 30/62 - loss 2.33760234 - samples/sec: 104.51 - lr: 0.100000\n",
            "2021-02-09 16:10:43,798 epoch 7 - iter 36/62 - loss 2.33531817 - samples/sec: 98.36 - lr: 0.100000\n",
            "2021-02-09 16:10:45,870 epoch 7 - iter 42/62 - loss 2.33815935 - samples/sec: 92.74 - lr: 0.100000\n",
            "2021-02-09 16:10:47,865 epoch 7 - iter 48/62 - loss 2.32548091 - samples/sec: 96.31 - lr: 0.100000\n",
            "2021-02-09 16:10:49,734 epoch 7 - iter 54/62 - loss 2.31651530 - samples/sec: 102.85 - lr: 0.100000\n",
            "2021-02-09 16:10:51,648 epoch 7 - iter 60/62 - loss 2.30086069 - samples/sec: 100.43 - lr: 0.100000\n",
            "2021-02-09 16:10:52,112 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:10:52,117 EPOCH 7 done: loss 2.3011 - lr 0.1000000\n",
            "2021-02-09 16:10:52,595 DEV : loss 2.3349645137786865 - score 0.4422\n",
            "2021-02-09 16:10:52,602 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-09 16:10:56,224 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:10:59,111 epoch 8 - iter 6/62 - loss 2.21750490 - samples/sec: 66.73 - lr: 0.100000\n",
            "2021-02-09 16:11:02,271 epoch 8 - iter 12/62 - loss 2.24700588 - samples/sec: 60.97 - lr: 0.100000\n",
            "2021-02-09 16:11:05,678 epoch 8 - iter 18/62 - loss 2.25694602 - samples/sec: 56.47 - lr: 0.100000\n",
            "2021-02-09 16:11:08,517 epoch 8 - iter 24/62 - loss 2.22601485 - samples/sec: 67.99 - lr: 0.100000\n",
            "2021-02-09 16:11:11,709 epoch 8 - iter 30/62 - loss 2.19705706 - samples/sec: 60.34 - lr: 0.100000\n",
            "2021-02-09 16:11:13,911 epoch 8 - iter 36/62 - loss 2.17129479 - samples/sec: 87.62 - lr: 0.100000\n",
            "2021-02-09 16:11:15,770 epoch 8 - iter 42/62 - loss 2.14144084 - samples/sec: 103.56 - lr: 0.100000\n",
            "2021-02-09 16:11:17,648 epoch 8 - iter 48/62 - loss 2.11763311 - samples/sec: 102.35 - lr: 0.100000\n",
            "2021-02-09 16:11:19,605 epoch 8 - iter 54/62 - loss 2.11392432 - samples/sec: 98.35 - lr: 0.100000\n",
            "2021-02-09 16:11:21,697 epoch 8 - iter 60/62 - loss 2.13374108 - samples/sec: 91.85 - lr: 0.100000\n",
            "2021-02-09 16:11:22,193 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:11:22,195 EPOCH 8 done: loss 2.1246 - lr 0.1000000\n",
            "2021-02-09 16:11:22,658 DEV : loss 2.2135519981384277 - score 0.4498\n",
            "2021-02-09 16:11:22,666 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-09 16:11:25,790 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:11:27,621 epoch 9 - iter 6/62 - loss 2.16128651 - samples/sec: 105.49 - lr: 0.100000\n",
            "2021-02-09 16:11:29,681 epoch 9 - iter 12/62 - loss 2.19019167 - samples/sec: 93.45 - lr: 0.100000\n",
            "2021-02-09 16:11:31,442 epoch 9 - iter 18/62 - loss 2.04031759 - samples/sec: 109.18 - lr: 0.100000\n",
            "2021-02-09 16:11:33,466 epoch 9 - iter 24/62 - loss 2.08748160 - samples/sec: 94.95 - lr: 0.100000\n",
            "2021-02-09 16:11:35,331 epoch 9 - iter 30/62 - loss 2.08361270 - samples/sec: 103.06 - lr: 0.100000\n",
            "2021-02-09 16:11:37,253 epoch 9 - iter 36/62 - loss 2.05980227 - samples/sec: 99.97 - lr: 0.100000\n",
            "2021-02-09 16:11:39,218 epoch 9 - iter 42/62 - loss 2.03833904 - samples/sec: 97.99 - lr: 0.100000\n",
            "2021-02-09 16:11:41,144 epoch 9 - iter 48/62 - loss 2.03964158 - samples/sec: 99.76 - lr: 0.100000\n",
            "2021-02-09 16:11:43,053 epoch 9 - iter 54/62 - loss 2.03481793 - samples/sec: 100.67 - lr: 0.100000\n",
            "2021-02-09 16:11:45,021 epoch 9 - iter 60/62 - loss 2.02592469 - samples/sec: 97.62 - lr: 0.100000\n",
            "2021-02-09 16:11:45,493 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:11:45,494 EPOCH 9 done: loss 2.0247 - lr 0.1000000\n",
            "2021-02-09 16:11:45,950 DEV : loss 2.002000093460083 - score 0.5089\n",
            "2021-02-09 16:11:45,954 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-09 16:11:48,750 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:11:50,630 epoch 10 - iter 6/62 - loss 1.88961180 - samples/sec: 102.46 - lr: 0.100000\n",
            "2021-02-09 16:11:52,556 epoch 10 - iter 12/62 - loss 1.91948551 - samples/sec: 99.95 - lr: 0.100000\n",
            "2021-02-09 16:11:54,491 epoch 10 - iter 18/62 - loss 1.91794979 - samples/sec: 99.34 - lr: 0.100000\n",
            "2021-02-09 16:11:56,522 epoch 10 - iter 24/62 - loss 1.96624376 - samples/sec: 94.60 - lr: 0.100000\n",
            "2021-02-09 16:11:58,539 epoch 10 - iter 30/62 - loss 1.93764838 - samples/sec: 95.53 - lr: 0.100000\n",
            "2021-02-09 16:12:00,490 epoch 10 - iter 36/62 - loss 1.94025959 - samples/sec: 98.50 - lr: 0.100000\n",
            "2021-02-09 16:12:02,493 epoch 10 - iter 42/62 - loss 1.95048573 - samples/sec: 96.06 - lr: 0.100000\n",
            "2021-02-09 16:12:04,432 epoch 10 - iter 48/62 - loss 1.92901571 - samples/sec: 99.12 - lr: 0.100000\n",
            "2021-02-09 16:12:06,357 epoch 10 - iter 54/62 - loss 1.92380389 - samples/sec: 99.84 - lr: 0.100000\n",
            "2021-02-09 16:12:08,365 epoch 10 - iter 60/62 - loss 1.91954116 - samples/sec: 95.69 - lr: 0.100000\n",
            "2021-02-09 16:12:08,881 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:12:08,882 EPOCH 10 done: loss 1.9218 - lr 0.1000000\n",
            "2021-02-09 16:12:09,401 DEV : loss 1.9206774234771729 - score 0.504\n",
            "2021-02-09 16:12:09,405 BAD EPOCHS (no improvement): 1\n",
            "2021-02-09 16:12:09,406 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:12:11,426 epoch 11 - iter 6/62 - loss 1.95945321 - samples/sec: 95.31 - lr: 0.100000\n",
            "2021-02-09 16:12:13,400 epoch 11 - iter 12/62 - loss 1.86200098 - samples/sec: 97.43 - lr: 0.100000\n",
            "2021-02-09 16:12:15,349 epoch 11 - iter 18/62 - loss 1.90193318 - samples/sec: 98.65 - lr: 0.100000\n",
            "2021-02-09 16:12:17,340 epoch 11 - iter 24/62 - loss 1.87493043 - samples/sec: 96.51 - lr: 0.100000\n",
            "2021-02-09 16:12:19,303 epoch 11 - iter 30/62 - loss 1.85650484 - samples/sec: 97.87 - lr: 0.100000\n",
            "2021-02-09 16:12:21,187 epoch 11 - iter 36/62 - loss 1.84431997 - samples/sec: 102.01 - lr: 0.100000\n",
            "2021-02-09 16:12:23,265 epoch 11 - iter 42/62 - loss 1.82934072 - samples/sec: 92.48 - lr: 0.100000\n",
            "2021-02-09 16:12:25,064 epoch 11 - iter 48/62 - loss 1.84434008 - samples/sec: 106.85 - lr: 0.100000\n",
            "2021-02-09 16:12:26,612 epoch 11 - iter 54/62 - loss 1.84977562 - samples/sec: 124.24 - lr: 0.100000\n",
            "2021-02-09 16:12:28,126 epoch 11 - iter 60/62 - loss 1.81532136 - samples/sec: 127.01 - lr: 0.100000\n",
            "2021-02-09 16:12:28,497 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:12:28,499 EPOCH 11 done: loss 1.8138 - lr 0.1000000\n",
            "2021-02-09 16:12:28,938 DEV : loss 1.8761351108551025 - score 0.5149\n",
            "2021-02-09 16:12:28,947 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-09 16:12:31,809 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:12:33,582 epoch 12 - iter 6/62 - loss 1.92469372 - samples/sec: 108.74 - lr: 0.100000\n",
            "2021-02-09 16:12:35,148 epoch 12 - iter 12/62 - loss 1.82657344 - samples/sec: 122.93 - lr: 0.100000\n",
            "2021-02-09 16:12:36,619 epoch 12 - iter 18/62 - loss 1.78120704 - samples/sec: 130.64 - lr: 0.100000\n",
            "2021-02-09 16:12:38,187 epoch 12 - iter 24/62 - loss 1.74788352 - samples/sec: 122.60 - lr: 0.100000\n",
            "2021-02-09 16:12:39,697 epoch 12 - iter 30/62 - loss 1.73423509 - samples/sec: 127.26 - lr: 0.100000\n",
            "2021-02-09 16:12:41,235 epoch 12 - iter 36/62 - loss 1.73216503 - samples/sec: 125.04 - lr: 0.100000\n",
            "2021-02-09 16:12:42,804 epoch 12 - iter 42/62 - loss 1.69731319 - samples/sec: 122.50 - lr: 0.100000\n",
            "2021-02-09 16:12:44,436 epoch 12 - iter 48/62 - loss 1.71474779 - samples/sec: 117.81 - lr: 0.100000\n",
            "2021-02-09 16:12:45,995 epoch 12 - iter 54/62 - loss 1.71438677 - samples/sec: 123.34 - lr: 0.100000\n",
            "2021-02-09 16:12:47,528 epoch 12 - iter 60/62 - loss 1.71739686 - samples/sec: 125.38 - lr: 0.100000\n",
            "2021-02-09 16:12:47,916 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:12:47,917 EPOCH 12 done: loss 1.7222 - lr 0.1000000\n",
            "2021-02-09 16:12:48,390 DEV : loss 1.8543308973312378 - score 0.4771\n",
            "2021-02-09 16:12:48,394 BAD EPOCHS (no improvement): 1\n",
            "2021-02-09 16:12:48,396 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:12:49,963 epoch 13 - iter 6/62 - loss 1.62729273 - samples/sec: 122.89 - lr: 0.100000\n",
            "2021-02-09 16:12:51,563 epoch 13 - iter 12/62 - loss 1.67360409 - samples/sec: 120.13 - lr: 0.100000\n",
            "2021-02-09 16:12:53,131 epoch 13 - iter 18/62 - loss 1.64158689 - samples/sec: 122.72 - lr: 0.100000\n",
            "2021-02-09 16:12:54,797 epoch 13 - iter 24/62 - loss 1.65700863 - samples/sec: 115.33 - lr: 0.100000\n",
            "2021-02-09 16:12:56,513 epoch 13 - iter 30/62 - loss 1.67178854 - samples/sec: 111.99 - lr: 0.100000\n",
            "2021-02-09 16:12:58,061 epoch 13 - iter 36/62 - loss 1.66336257 - samples/sec: 124.21 - lr: 0.100000\n",
            "2021-02-09 16:12:59,629 epoch 13 - iter 42/62 - loss 1.66105047 - samples/sec: 122.61 - lr: 0.100000\n",
            "2021-02-09 16:13:01,164 epoch 13 - iter 48/62 - loss 1.66549274 - samples/sec: 125.22 - lr: 0.100000\n",
            "2021-02-09 16:13:02,766 epoch 13 - iter 54/62 - loss 1.66707191 - samples/sec: 119.95 - lr: 0.100000\n",
            "2021-02-09 16:13:04,339 epoch 13 - iter 60/62 - loss 1.67729470 - samples/sec: 122.24 - lr: 0.100000\n",
            "2021-02-09 16:13:04,744 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:13:04,745 EPOCH 13 done: loss 1.6817 - lr 0.1000000\n",
            "2021-02-09 16:13:05,214 DEV : loss 1.6676126718521118 - score 0.5451\n",
            "2021-02-09 16:13:05,221 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-09 16:13:08,098 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:13:09,723 epoch 14 - iter 6/62 - loss 1.62873471 - samples/sec: 118.82 - lr: 0.100000\n",
            "2021-02-09 16:13:11,344 epoch 14 - iter 12/62 - loss 1.66168688 - samples/sec: 118.84 - lr: 0.100000\n",
            "2021-02-09 16:13:12,919 epoch 14 - iter 18/62 - loss 1.67101350 - samples/sec: 121.99 - lr: 0.100000\n",
            "2021-02-09 16:13:14,559 epoch 14 - iter 24/62 - loss 1.67162470 - samples/sec: 117.22 - lr: 0.100000\n",
            "2021-02-09 16:13:16,141 epoch 14 - iter 30/62 - loss 1.70048589 - samples/sec: 121.52 - lr: 0.100000\n",
            "2021-02-09 16:13:17,659 epoch 14 - iter 36/62 - loss 1.65065299 - samples/sec: 126.58 - lr: 0.100000\n",
            "2021-02-09 16:13:19,260 epoch 14 - iter 42/62 - loss 1.63029068 - samples/sec: 120.09 - lr: 0.100000\n",
            "2021-02-09 16:13:20,887 epoch 14 - iter 48/62 - loss 1.62685893 - samples/sec: 118.06 - lr: 0.100000\n",
            "2021-02-09 16:13:22,491 epoch 14 - iter 54/62 - loss 1.61451457 - samples/sec: 119.93 - lr: 0.100000\n",
            "2021-02-09 16:13:24,062 epoch 14 - iter 60/62 - loss 1.60911592 - samples/sec: 122.29 - lr: 0.100000\n",
            "2021-02-09 16:13:24,446 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:13:24,448 EPOCH 14 done: loss 1.6044 - lr 0.1000000\n",
            "2021-02-09 16:13:24,942 DEV : loss 1.5935313701629639 - score 0.5501\n",
            "2021-02-09 16:13:24,947 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-09 16:13:27,771 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:13:29,386 epoch 15 - iter 6/62 - loss 1.51711637 - samples/sec: 120.05 - lr: 0.100000\n",
            "2021-02-09 16:13:31,027 epoch 15 - iter 12/62 - loss 1.56346136 - samples/sec: 117.35 - lr: 0.100000\n",
            "2021-02-09 16:13:32,579 epoch 15 - iter 18/62 - loss 1.52694350 - samples/sec: 123.90 - lr: 0.100000\n",
            "2021-02-09 16:13:34,123 epoch 15 - iter 24/62 - loss 1.56878578 - samples/sec: 124.42 - lr: 0.100000\n",
            "2021-02-09 16:13:35,718 epoch 15 - iter 30/62 - loss 1.53014072 - samples/sec: 120.88 - lr: 0.100000\n",
            "2021-02-09 16:13:37,287 epoch 15 - iter 36/62 - loss 1.55175118 - samples/sec: 122.58 - lr: 0.100000\n",
            "2021-02-09 16:13:38,892 epoch 15 - iter 42/62 - loss 1.55051638 - samples/sec: 119.75 - lr: 0.100000\n",
            "2021-02-09 16:13:40,450 epoch 15 - iter 48/62 - loss 1.54405015 - samples/sec: 123.52 - lr: 0.100000\n",
            "2021-02-09 16:13:42,017 epoch 15 - iter 54/62 - loss 1.54348707 - samples/sec: 122.61 - lr: 0.100000\n",
            "2021-02-09 16:13:43,583 epoch 15 - iter 60/62 - loss 1.53623474 - samples/sec: 122.81 - lr: 0.100000\n",
            "2021-02-09 16:13:43,977 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:13:43,978 EPOCH 15 done: loss 1.5393 - lr 0.1000000\n",
            "2021-02-09 16:13:44,433 DEV : loss 1.5411202907562256 - score 0.5455\n",
            "2021-02-09 16:13:44,440 BAD EPOCHS (no improvement): 1\n",
            "2021-02-09 16:13:44,442 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:13:46,010 epoch 16 - iter 6/62 - loss 1.41784853 - samples/sec: 122.64 - lr: 0.100000\n",
            "2021-02-09 16:13:47,613 epoch 16 - iter 12/62 - loss 1.44493139 - samples/sec: 119.96 - lr: 0.100000\n",
            "2021-02-09 16:13:49,188 epoch 16 - iter 18/62 - loss 1.51586752 - samples/sec: 122.00 - lr: 0.100000\n",
            "2021-02-09 16:13:50,820 epoch 16 - iter 24/62 - loss 1.53319873 - samples/sec: 117.86 - lr: 0.100000\n",
            "2021-02-09 16:13:52,374 epoch 16 - iter 30/62 - loss 1.53299916 - samples/sec: 123.68 - lr: 0.100000\n",
            "2021-02-09 16:13:53,890 epoch 16 - iter 36/62 - loss 1.53429387 - samples/sec: 126.96 - lr: 0.100000\n",
            "2021-02-09 16:13:55,460 epoch 16 - iter 42/62 - loss 1.53111872 - samples/sec: 122.37 - lr: 0.100000\n",
            "2021-02-09 16:13:57,040 epoch 16 - iter 48/62 - loss 1.52367580 - samples/sec: 121.70 - lr: 0.100000\n",
            "2021-02-09 16:13:58,633 epoch 16 - iter 54/62 - loss 1.52134559 - samples/sec: 120.64 - lr: 0.100000\n",
            "2021-02-09 16:14:00,225 epoch 16 - iter 60/62 - loss 1.51073781 - samples/sec: 120.76 - lr: 0.100000\n",
            "2021-02-09 16:14:00,609 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:14:00,610 EPOCH 16 done: loss 1.5192 - lr 0.1000000\n",
            "2021-02-09 16:14:01,083 DEV : loss 1.4952017068862915 - score 0.5725\n",
            "2021-02-09 16:14:01,091 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-09 16:14:03,842 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:14:05,514 epoch 17 - iter 6/62 - loss 1.54211360 - samples/sec: 115.57 - lr: 0.100000\n",
            "2021-02-09 16:14:07,100 epoch 17 - iter 12/62 - loss 1.50124226 - samples/sec: 121.36 - lr: 0.100000\n",
            "2021-02-09 16:14:08,783 epoch 17 - iter 18/62 - loss 1.47191076 - samples/sec: 114.22 - lr: 0.100000\n",
            "2021-02-09 16:14:10,412 epoch 17 - iter 24/62 - loss 1.45939400 - samples/sec: 118.13 - lr: 0.100000\n",
            "2021-02-09 16:14:11,978 epoch 17 - iter 30/62 - loss 1.45352354 - samples/sec: 122.78 - lr: 0.100000\n",
            "2021-02-09 16:14:13,658 epoch 17 - iter 36/62 - loss 1.48531560 - samples/sec: 114.39 - lr: 0.100000\n",
            "2021-02-09 16:14:15,188 epoch 17 - iter 42/62 - loss 1.49272489 - samples/sec: 125.68 - lr: 0.100000\n",
            "2021-02-09 16:14:16,731 epoch 17 - iter 48/62 - loss 1.47875018 - samples/sec: 124.81 - lr: 0.100000\n",
            "2021-02-09 16:14:18,384 epoch 17 - iter 54/62 - loss 1.47964299 - samples/sec: 116.49 - lr: 0.100000\n",
            "2021-02-09 16:14:19,989 epoch 17 - iter 60/62 - loss 1.48403100 - samples/sec: 119.77 - lr: 0.100000\n",
            "2021-02-09 16:14:20,390 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:14:20,392 EPOCH 17 done: loss 1.4738 - lr 0.1000000\n",
            "2021-02-09 16:14:20,863 DEV : loss 1.466404914855957 - score 0.5799\n",
            "2021-02-09 16:14:20,868 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-09 16:14:23,652 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:14:25,375 epoch 18 - iter 6/62 - loss 1.48681424 - samples/sec: 111.85 - lr: 0.100000\n",
            "2021-02-09 16:14:26,993 epoch 18 - iter 12/62 - loss 1.47698426 - samples/sec: 118.79 - lr: 0.100000\n",
            "2021-02-09 16:14:28,558 epoch 18 - iter 18/62 - loss 1.44860442 - samples/sec: 122.82 - lr: 0.100000\n",
            "2021-02-09 16:14:30,214 epoch 18 - iter 24/62 - loss 1.44823839 - samples/sec: 116.04 - lr: 0.100000\n",
            "2021-02-09 16:14:31,833 epoch 18 - iter 30/62 - loss 1.43197082 - samples/sec: 118.94 - lr: 0.100000\n",
            "2021-02-09 16:14:33,446 epoch 18 - iter 36/62 - loss 1.41556441 - samples/sec: 119.22 - lr: 0.100000\n",
            "2021-02-09 16:14:35,105 epoch 18 - iter 42/62 - loss 1.41437070 - samples/sec: 115.81 - lr: 0.100000\n",
            "2021-02-09 16:14:36,800 epoch 18 - iter 48/62 - loss 1.42245396 - samples/sec: 113.37 - lr: 0.100000\n",
            "2021-02-09 16:14:38,470 epoch 18 - iter 54/62 - loss 1.43178918 - samples/sec: 115.25 - lr: 0.100000\n",
            "2021-02-09 16:14:40,134 epoch 18 - iter 60/62 - loss 1.44418940 - samples/sec: 115.47 - lr: 0.100000\n",
            "2021-02-09 16:14:40,497 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:14:40,498 EPOCH 18 done: loss 1.4415 - lr 0.1000000\n",
            "2021-02-09 16:14:40,985 DEV : loss 1.451919674873352 - score 0.5753\n",
            "2021-02-09 16:14:40,993 BAD EPOCHS (no improvement): 1\n",
            "2021-02-09 16:14:40,995 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:14:42,662 epoch 19 - iter 6/62 - loss 1.35678871 - samples/sec: 115.39 - lr: 0.100000\n",
            "2021-02-09 16:14:44,192 epoch 19 - iter 12/62 - loss 1.32184277 - samples/sec: 125.59 - lr: 0.100000\n",
            "2021-02-09 16:14:45,823 epoch 19 - iter 18/62 - loss 1.38547383 - samples/sec: 117.86 - lr: 0.100000\n",
            "2021-02-09 16:14:47,414 epoch 19 - iter 24/62 - loss 1.37969337 - samples/sec: 120.81 - lr: 0.100000\n",
            "2021-02-09 16:14:49,030 epoch 19 - iter 30/62 - loss 1.37830933 - samples/sec: 118.97 - lr: 0.100000\n",
            "2021-02-09 16:14:50,591 epoch 19 - iter 36/62 - loss 1.38598829 - samples/sec: 123.14 - lr: 0.100000\n",
            "2021-02-09 16:14:52,282 epoch 19 - iter 42/62 - loss 1.39648980 - samples/sec: 113.62 - lr: 0.100000\n",
            "2021-02-09 16:14:53,933 epoch 19 - iter 48/62 - loss 1.39804929 - samples/sec: 116.40 - lr: 0.100000\n",
            "2021-02-09 16:14:55,490 epoch 19 - iter 54/62 - loss 1.38961936 - samples/sec: 123.46 - lr: 0.100000\n",
            "2021-02-09 16:14:57,202 epoch 19 - iter 60/62 - loss 1.39229380 - samples/sec: 112.29 - lr: 0.100000\n",
            "2021-02-09 16:14:57,602 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:14:57,603 EPOCH 19 done: loss 1.3976 - lr 0.1000000\n",
            "2021-02-09 16:14:58,102 DEV : loss 1.4099966287612915 - score 0.5748\n",
            "2021-02-09 16:14:58,112 BAD EPOCHS (no improvement): 2\n",
            "2021-02-09 16:14:58,116 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:14:59,766 epoch 20 - iter 6/62 - loss 1.48522538 - samples/sec: 116.58 - lr: 0.100000\n",
            "2021-02-09 16:15:01,408 epoch 20 - iter 12/62 - loss 1.41769737 - samples/sec: 117.00 - lr: 0.100000\n",
            "2021-02-09 16:15:03,111 epoch 20 - iter 18/62 - loss 1.42063465 - samples/sec: 112.90 - lr: 0.100000\n",
            "2021-02-09 16:15:04,881 epoch 20 - iter 24/62 - loss 1.40647708 - samples/sec: 108.79 - lr: 0.100000\n",
            "2021-02-09 16:15:06,503 epoch 20 - iter 30/62 - loss 1.41275714 - samples/sec: 118.55 - lr: 0.100000\n",
            "2021-02-09 16:15:08,155 epoch 20 - iter 36/62 - loss 1.39652014 - samples/sec: 116.30 - lr: 0.100000\n",
            "2021-02-09 16:15:09,808 epoch 20 - iter 42/62 - loss 1.38222156 - samples/sec: 116.44 - lr: 0.100000\n",
            "2021-02-09 16:15:11,527 epoch 20 - iter 48/62 - loss 1.37393944 - samples/sec: 111.77 - lr: 0.100000\n",
            "2021-02-09 16:15:13,128 epoch 20 - iter 54/62 - loss 1.38098371 - samples/sec: 120.07 - lr: 0.100000\n",
            "2021-02-09 16:15:14,877 epoch 20 - iter 60/62 - loss 1.38093476 - samples/sec: 109.87 - lr: 0.100000\n",
            "2021-02-09 16:15:15,304 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:15:15,305 EPOCH 20 done: loss 1.3784 - lr 0.1000000\n",
            "2021-02-09 16:15:15,767 DEV : loss 1.3439245223999023 - score 0.5882\n",
            "2021-02-09 16:15:15,775 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-09 16:15:21,717 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-09 16:15:21,725 Testing using best model ...\n",
            "2021-02-09 16:15:21,727 loading file models/baseline-charembeddings/best-model.pt\n",
            "2021-02-09 16:15:24,793 0.6228\t0.6208\t0.6218\n",
            "2021-02-09 16:15:24,795 \n",
            "Results:\n",
            "- F1-score (micro) 0.6218\n",
            "- F1-score (macro) 0.4369\n",
            "\n",
            "By class:\n",
            "BOOK       tp: 10 - fp: 10 - fn: 41 - precision: 0.5000 - recall: 0.1961 - f1-score: 0.2817\n",
            "COMPOSER   tp: 9 - fp: 7 - fn: 50 - precision: 0.5625 - recall: 0.1525 - f1-score: 0.2400\n",
            "FILM       tp: 10 - fp: 2 - fn: 65 - precision: 0.8333 - recall: 0.1333 - f1-score: 0.2299\n",
            "SINGER     tp: 233 - fp: 194 - fn: 16 - precision: 0.5457 - recall: 0.9357 - f1-score: 0.6893\n",
            "SONG       tp: 126 - fp: 22 - fn: 65 - precision: 0.8514 - recall: 0.6597 - f1-score: 0.7434\n",
            "2021-02-09 16:15:24,795 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r4TZgl0cFpp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}